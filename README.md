# 文档查重
## 一、项目介绍
本项目代码功能主要是将`输入的文档`与`存储在ElasticSearch中的文档`进行查重，返回相似度高的内容。

## 二、项目文件
`main.py`是项目的主文件，主要是配置es数据库地址、要查重的文档等信息。

`copy_detection.py`是查重检测功能代码，主要包含了对输入文档按照token数进行分块，随后按块进行文本相似度和语义相似度两方面的检测。
文本相似度是通过计算输入句子与数据库中的文档句子Jaccard相似度来实现，语义相似度是通过调用`hanlp`库来评估两个句子的语义实现。

`create_index.py`是创建es数据库中的索引(Index)。

`store_docs.py`能够将文档存储到es数据库中，支持对文件夹中文档的批量操作。

`utils.py`中主要放有一些工具函数，比如获取文档的内容、分句、计算tf-idf、检索数据库等。

`stopwords.txt`是常见的中文停用词。


## 三、运行说明
首先执行`pip install -r requirements.txt`按照所需包。

然后利用`create_index.py`和`store_docs.py`中的函数创建索引、存储文档。

随后在`main.py`中填写好部署的elasticsearch数据库的地址、用户名、密码等信息，选择需要检索的本地文档，选择要在es数据库中的哪个索引中去检索，
计算文本相似度还是语义相似度，文档分块数量，最后运行即可。

运行程序，首先会将输入文档分块，随后并行与数据库中文档进行比对，如果相似度超过阈值（阈值默认文本相似度为0.5，语义相似度为0.7），
则会将该句子对加入到结果中，最后返回。

## 四、运行结果
运行结束会输出`Sentence '{i}' has a {sim:.3f} similarity to Sentence '{k}' in Document '{j}'`，其中{i}是输入文档中的原句，
{k}是数据库中检测到的与句子{i}相似度较高的句子，{j}是{k}的出处，{sim:.3f}是它们的相似度（文本或语义，保留三位小数）。